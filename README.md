# üçø Popcorn

GPU programming is still too hard, and the current LLMs aren't helping much. We think we can build something better, an LLM that can actually write good GPU code.

We're doing this in public - all our training runs, conversations, and infrastructure will be open.

## Where to Find Us
We mostly talk on discord.gg/gpumode in the popcorn channel.


## What We're Working On
### Data
We're collecting and synthetically generating as many GPU kernels as we can.

### Infrastructure
We need compute - we're building tools to track progress and share results in real-time through Discord.

### Research
We're investigating how to prompt, train, deploy, and sample LLMs for effective GPU code generation.

### Language Design
We're exploring new abstractions to simplify GPU programming.


## Things we've built
* KernelBench: https://github.com/ScalingIntelligence/KernelBench
* KernelBot: https://www.gpumode.com/
* KernelBot Dataset: https://huggingface.co/datasets/GPUMODE/kernelbot-data
* KernelBook: https://huggingface.co/GPUMODE
* ThunderKittens: https://github.com/HazyResearch/ThunderKittens
* KernelLLM: https://huggingface.co/facebook/KernelLLM



## Collaborators and Sponsors
Our collaborators
* https://scalingintelligence.stanford.edu/
* https://hazyresearch.stanford.edu/
* https://pytorch.org/
* https://discord.com/invite/gpumode

Our compute sponsors
* https://nebius.com/
* https://www.nvidia.com/
* https://www.amd.com/
* https://modal.com/

And anyone who shares our goals is welcome to join
