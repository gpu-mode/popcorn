# üçø Popcorn

GPU programming is still too hard, and the current LLMs aren't helping much. We think we can build something better, an LLM that can actually write good GPU code.

We're doing this in public because,honestly it would be too hard to do otherwise. All our training runs, our conversations about what works and what doesn't, our infrastructure - it's all going to be open. If you want to help figure this out, join us.

## Where to Find Us
We mostly talk on discord.gg/gpumode in the popcorn channel. It's pretty casual - drop in when you can.

## What We're Working On

### Data
We're collecting every CUDA and Triton kernel we can find. We need more examples of good GPU code than what's currently out there. We're also building proper benchmarks so we can actually tell if what we're doing is working.

### Infrastructure
We need compute - we're building tools to track progress and share results in real-time through Discord.

### Research
We're trying to figure out the fundamentals - what do we need to tell an LLM about GPUs for it to write good code? How many times should we sample to get better results? What feedback actually helps?

### Language Design
We think some abstractions like Thunderkittens might make this whole thing easier. If that proves true, we'll push to get more people using and improving these tools.

## Collaborators and Sponsors

Our collaborators include
* https://scalingintelligence.stanford.edu/
* https://hazyresearch.stanford.edu/
* https://pytorch.org/
* https://discord.com/invite/gpumode

Our compute sponsors include
* https://nebius.com/
* https://www.nvidia.com/
* https://www.amd.com/
* https://modal.com/

And anyone who shares our goals is welcome to join
